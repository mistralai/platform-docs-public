---
id: changelog
title: Changelog
sidebar_position: 1.8
---
February 17, 2025
- We released Mistral Saba 25.02 (`mistral-saba-2502`).

January 30, 2025
- We released Mistral Small 25.01 (`mistral-small-2501`).

January 28, 2025
- We released custom [structured outputs](/capabilities/structured-output/custom_structured_output) for all models.

January 13, 2025
- We released Codestral 25.01 (`codestral-2501`).

November 18, 2024
- We released Mistral Large 24.11 (`mistral-large-2411`) and Pixtral Large (`pixtral-large-2411`). 
- [Le Chat](https://chat.mistral.ai/): 
    - Web search with citations
    - Canvas for ideation, in-line editing, and export
    - State of the art document and image understanding, powered by the new multimodal Pixtral Large 
    - Image generation, powered by Black Forest Labs Flux Pro
    - Fully integrated offering, from models to outputs
    - Faster responses powered by speculative editing

November 6, 2024
- We released moderation API and batch API. 
- We introduced three new parameters:
    - `presence_penalty`: penalizes the repetition of words or phrases
    - `frequency_penalty`: penalizes the repetition of words based on their frequency in the generated text
    - `n`: number of completions to return for each request, input tokens are only billed once. 

November 6, 2024
- We downscaled the temperature parameter of `pixtral-12b`, `ministral-3b-2410`, and `ministral-8b-2410` by a multiplier of 0.43 to improve consistency, quality, and unify model behavior.

October 9, 2024
- We released Ministral 3B (`ministral-3b-2410`) and Ministral 8B (`ministral-8b-2410`). 

September 17, 2024
- We released Pixtral (`pixtral-12b-2409`) and Mistral Small v24.09 (`mistral-small-2409`).
- We reduced price on our flagship model, Mistral Large 2.
- We introduced a free API tier on La Plateforme. 

September 13, 2024
- In le Chat, we added a mitigation against an obfuscated prompt method that could lead to data exfiltration, reported by researchers [Xiaohan Fu](https://xhfu.me/) and Earlence Fernandes. The attack required users to willingfully copy and paste adversarial prompts and provide personal data to the model. No user was impacted and no data was exfiltrated.

July 29, 2024
- We released version 1.0 of our Python and JS SDKs with major upgrades and syntax changes. Check out our [migration guide](https://github.com/mistralai/client-python/blob/main/MIGRATION.md) for details. 
- We released Agents API. See details [here](/capabilities/agents/). 

July 24, 2024
- We released Mistral Large 2 (`mistral-large-2407`).
- We added fine-tuning support for Codestral, Mistral Nemo and Mistral Large. Now the model choices for fine-tuning are `open-mistral-7b` (v0.3), `mistral-small-latest` (`mistral-small-2402`), `codestral-latest` (`codestral-2405`), `open-mistral-nemo` and , `mistral-large-latest` (`mistral-large-2407`)

July 18, 2024
- We released Mistral Nemo (`open-mistral-nemo`). 

July 16, 2024
- We released Codestral Mamba (`open-codestral-mamba`) and Mathstral. 

Jun 5, 2024
- We released fine-tuning API. Check out the [capability docs](/capabilities/finetuning/) and [guides](/guides/finetuning/). 

May 29, 2024
- New model available: `codestral-latest` (aka `codestral-2405`). Check out the code generation [docs](/capabilities/code_generation/). 

May 23, 2024

- Function calling: `tool_call_id` is now mandatory in chat messages with the
`tool` role.

Apr. 17, 2024

- New model available: `open-mixtral-8x22b` (aka `open-mixtral-8x22b-2404`). Check the release [blog](https://mistral.ai/news/mixtral-8x22b/) for details. 
- For function calling, `tool_call_id` must not be null for `open-mixtral-8x22b`.
- We released three versions of tokenizers for commercial and open-weight models: check the related [guide](../../guides/tokenization) and [repo](https://github.com/mistralai/mistral-common) for more details.

Mar. 28, 2024
- JSON mode now available for all models on La Plateforme. 

Feb. 26, 2024

- API endpoints: We renamed 3 API endpoints and added 2 model endpoints. 
    - `open-mistral-7b` (aka `mistral-tiny-2312`): renamed from `mistral-tiny`. The endpoint `mistral-tiny` will be deprecated in three months.
    - `open-mixtral-8x7B` (aka `mistral-small-2312`): renamed from `mistral-small`. The endpoint `mistral-small` will be deprecated in three months.
    - `mistral-small-latest` (aka `mistral-small-2402`): new model.
   - `mistral-medium-latest` (aka `mistral-medium-2312`): old model. The previous `mistral-medium` has been dated and tagged as `mistral-medium-2312`. The endpoint `mistral-medium` will be deprecated in three months.
    - `mistral-large-latest` (aka `mistral-large-2402`): our new flagship model with leading performance. 

- New API capabilities:
    - [Function calling](/capabilities/function_calling): available for Mistral Small and Mistral Large. 
    - [JSON mode](/capabilities/structured-output/json_mode): available for Mistral Small and Mistral Large

- [La Plateforme](https://console.mistral.ai/):
    - We added multiple currency support to the payment system, including the option to pay in US dollars. 
    - We introduced enterprise platform features including admin management, which allows users to manage individuals from your organization.

- [Le Chat](https://chat.mistral.ai/): 
    - We introduced the brand new chat interface Le Chat to easily interact with Mistral models. 
    - You can currently interact with three models: Mistral Large, Mistral Next, and Mistral Small. 

Jan. 11, 2024
- We have enhanced the API's strictness. Previously the API would silently ignores unsupported parameters in the requests, but it now strictly enforces the validity of all parameters. If you have unsupported parameters in your request, you will see the error message "Extra inputs are not permitted".
- A previous version of the [guardrailing documentation](/capabilities/guardrailing) incorrectly referred to the API parameter as `safe_mode` instead of `safe_prompt`. We corrected this in the documentation. 

Jan. 16, 2024
- We added token usage information in streaming requests. You can find it in the last chunk returned.
