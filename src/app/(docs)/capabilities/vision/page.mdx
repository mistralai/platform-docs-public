---
id: vision
title: Vision
sidebar_position: 2
---

import { Tabs, TabItem } from '@/components/common/multi-codeblock';
import { SectionTab } from '@/components/layout/section-tab';
import { Faq, FaqItem } from '@/components/common/faq';
import { ExplorerTabs, ExplorerTab } from '@/components/common/explorer-tabs';

import PassingImageUrlTab from './passing_image_url_tab/_page.mdx';
import PassingBase64EncodedImageTab from './passing_base64_encoded_image_tab/_page.mdx';

import UnderstandChartsTab from './understand_charts_tab/_page.mdx';
import CompareImagesTab from './compare_images_tab/_page.mdx';
import TranscribeReceiptsTab from './transcribe_receipts_tab/_page.mdx';
import OCROldDocumentsTab from './ocr_old_documents_tab/_page.mdx';
import OCRWithStructuredOutputTab from './ocr_with_structured_output_tab/_page.mdx';

# Vision

Vision capabilities enable models to **analyze images and provide insights based on visual content** in addition to text. This multimodal approach opens up new possibilities for applications that require both textual and visual understanding.

We provide a variety of models with vision capabilities, all available via the Chat Completions API.

:::tip
For more specific use cases regarding Document Parsing, OCR and Data Extraction we recommend taking a look at our Document AI stack [here](./document_ai).
:::

<SectionTab as="h1" sectionId="models">Models with Vision Capabilities</SectionTab>

- **Pixtral 12B** via `pixtral-12b-latest`
- **Pixtral Large** via `pixtral-large-latest`
- **Mistral Medium 3.1** via `mistral-medium-2508`
- **Mistral Small 3.2** via `mistral-small-2506`

<SectionTab as="h1" sectionId="passing-an-image">Sending an Image</SectionTab>

There are two ways to send an image to the Chat Completions API, either by passing a URL or by passing a base64 encoded image.

:::tip
Before continuing, we recommend reading the [Chat Competions](completion) documentation to learn more about the chat completions API and how to use it before proceeding.
:::

<ExplorerTabs>
  <ExplorerTab value="passing-an-image-url" label="Passing an Image URL">
    <PassingImageUrlTab/>
  </ExplorerTab>
  <ExplorerTab value="passing-a-base64-encoded-image" label="Passing a Base64 Encoded Image">
    <PassingBase64EncodedImageTab/>
  </ExplorerTab>
</ExplorerTabs>

<SectionTab as="h1" sectionId="use-cases">Use cases</SectionTab>

Below you can find a few examples of use cases leveraging our models vision, from understanding graphs to extract data, the use cases are diverse.

:::note
These are simple examples you can use as inspiration to build your own use cases, for OCR and Structured Outputs, we recommend leveraging [Document AI](./document_ai/document_ai_overview) and [Document AI Annotations](./document_ai/annotations).
:::

<ExplorerTabs mode="close">
  <ExplorerTab value="understand-charts" label="Charts">
    <UnderstandChartsTab/>
  </ExplorerTab>
  <ExplorerTab value="compare-images" label="Compare images">
    <CompareImagesTab/>
  </ExplorerTab>
  <ExplorerTab value="transcribe-receipts" label="Transcribe">
    <TranscribeReceiptsTab/>
  </ExplorerTab>
  <ExplorerTab value="ocr-old-documents" label="OCR Old Documents">
    <OCROldDocumentsTab/>
  </ExplorerTab>
  <ExplorerTab value="ocr-with-structured-output" label="OCR with Structured output">
    <OCRWithStructuredOutputTab/>
  </ExplorerTab>
</ExplorerTabs>

<SectionTab as="h1" sectionId="faq">FAQ</SectionTab>

<Faq defaultValue={['price-per-image', 'tokens-per-image']}>
  <FaqItem question="What is the price per image?">

    The price is calculated using the same pricing as input tokens per image, with each image being tokenized.

  </FaqItem>
  <FaqItem question="How many tokens correspond to an image and/or what is the maximum resolution?">

    Depending on the model and resolution, an image will be tokenized differently. Below is a summary.

    | Model             | Max Resolution | ≈ Formula                             | ≈ N Max Tokens |
    | ----------------- | -------------- | ------------------------------------- | -------------- |
    | Mistral Small 3.2 | 1540x1540      | `≈ (ResolutionX * ResolutionY) / 784` | ≈ 3025         |
    | Mistral Medium 3  | 1540x1540      | `≈ (ResolutionX * ResolutionY) / 784` | ≈ 3025         |
    | Mistral Small 3.1 | 1540x1540      | `≈ (ResolutionX * ResolutionY) / 784` | ≈ 3025         |
    | Pixtral Large     | 1024x1024      | `≈ (ResolutionX * ResolutionY) / 256` | ≈ 4096         |
    | Pixtral 12B       | 1024x1024      | `≈ (ResolutionX * ResolutionY) / 256` | ≈ 4096         |

    If the resolution of the image sent is higher than the maximum resolution of the model, the image will be downscaled to its maximum resolution. An error will be sent if the resolution is higher than **10000x10000**.

  </FaqItem>
  <FaqItem question="Can I fine-tune the image capabilities?">

    Yes, you can fine-tune pixtral-12b.

  </FaqItem>
  <FaqItem question="Can I use them to generate images?">

    No, they are designed to understand and analyze images, not to generate them.

  </FaqItem>
  <FaqItem question="What types of image files are supported?">

    We currently support the following image formats:

    - PNG (.png)
    - JPEG (.jpeg and .jpg)
    - WEBP (.webp)
    - Non-animated GIF with only one frame (.gif)

  </FaqItem>

  <FaqItem question="Is there a limit to the size of the image?">

    The current file size limit is 10Mb.

  </FaqItem>
  <FaqItem question="What's the maximum number images per request?">

    The maximum number images per request via API is 8.

  </FaqItem>
  <FaqItem question="What is the rate limit?">

    For information on rate limits, please visit https://console.mistral.ai/limits/.

  </FaqItem>
</Faq>
