---
id: audio
title: Audio & Transcription
sidebar_position: 3
---
import { Tabs, TabItem } from '@/components/common/multi-codeblock';
import { SectionTab } from '@/components/layout/section-tab';
import { Faq, FaqItem } from '@/components/common/faq';
import { ExplorerTabs, ExplorerTab } from '@/components/common/explorer-tabs';

import PassingAudioFileTab from './passing_audio_file_tab/_page.mdx';
import PassingAudioURLTab from './passing_audio_url_tab/_page.mdx';
import PassingUploadedAudioFileTab from './passing_uploaded_audio_file_tab/_page.mdx';

import ChatTab from './chat_tab/_page.mdx';
import MusicTab from './music_tab/_page.mdx';
import CompareSpeakersTab from './compare_speakers_tab/_page.mdx';

import PassingTranscriptionAudioFileTab from './passing_transcription_audio_file_tab/_page.mdx';
import PassingTranscriptionAudioURLTab from './passing_transcription_audio_url_tab/_page.mdx';
import PassingTranscriptionUploadedAudioFileTab from './passing_transcription_uploaded_audio_file_tab/_page.mdx';
import TranscriptionWithTimestampsSection from './transcription_with_timestamps_section/_page.mdx'
import RealtimeTranscriptionSection from './realtime_transcription_section/_page.mdx'
import ContextBiasingSection from './context_biasing_transcription_section/_page.mdx'

import ObamaTab from './obama_tab/_page.mdx';

# Audio & Transcription

Audio input capabilities enable models to chat and understand audio directly, this can be used for both chat use cases via audio or for optimal transcription purposes.

<Image
  url={['/img/audio.png', '/img/audio_dark.png']}
  alt="audio_graph"
  width="500px"
  centered
/>

<SectionTab as="h1" sectionId="before-you-start">Before You Start</SectionTab>

### Models with Audio Capabilities

Audio capable models:
- **Voxtral Small** (`voxtral-small-latest`) with audio input for [chat](#chat-with-audio) use cases.
- **Voxtral Mini** (`voxtral-mini-latest`) with audio input for [chat](#chat-with-audio) use cases
- And **Voxtral Mini Transcribe** (`voxtral-mini-latest` via `audio/transcriptions`), with an efficient [transcription](#transcription) only service.

:::note
- `voxtral-mini-latest` for chat points to `voxtral-mini-2507`
- `voxtral-mini-latest` for transcription points to `voxtral-mini-2602`
:::

:::tip
For faster transcription time, we recommend uploading your audio files.
:::

<SectionTab as="h1" sectionId="models">Chat with Audio</SectionTab>

### Use Audio with Instruction Following models

Our Voxtral models are capable of being used for chat use cases with our chat completions endpoint.

:::tip
Before continuing, we recommend reading the [Chat Completions](completion) documentation to learn more about the chat completions API and how to use it before proceeding.
:::


<ExplorerTabs id="chat-with-audio">
  <ExplorerTab value="passing-an-audio-file" label="Passing an Audio File in Base64">
    <PassingAudioFileTab/>
  </ExplorerTab>
  <ExplorerTab value="passing-an-audio-url" label="Passing an Audio URL">
    <PassingAudioURLTab/>
  </ExplorerTab>
  <ExplorerTab value="passing-an-uploaded-audio-file" label="Passing an Uploaded Audio File">
    <PassingUploadedAudioFileTab/>
  </ExplorerTab>
</ExplorerTabs>

<SectionTab as="h2" variant="secondary" sectionId="example-samples">Example Samples</SectionTab>

Below you can find a few of the multiple use cases possible, by leveraging the audio capabilities of our models.

<ExplorerTabs id="audio-transcription-2" mode="close">
  <ExplorerTab value="chat" label="Chat">
    <ChatTab/>
  </ExplorerTab>
  <ExplorerTab value="music" label="Music">
    <MusicTab/>
  </ExplorerTab>
  <ExplorerTab value="compare-speakers" label="Compare Speakers">
    <CompareSpeakersTab/>
  </ExplorerTab>
</ExplorerTabs>

<SectionTab as="h1" sectionId="transcription">Transcription</SectionTab>

### Transcribe any Audio

Transcription provides an optimized endpoint for transcription purposes and currently supports `voxtral-mini-latest`, which runs **Voxtral Mini Transcribe**.

**Parameters**  
We provide different settings and parameters for transcription, such as:
- `timestamp_granularities`: This allows you to set timestamps to track not only "what" was said but also "when". You can find more about timestamps [here](#transcription-with-timestamps).
- `diarize`: This allows you to keep track of who is talking.
- `context_bias`: Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental. You can find more about context biasing [here](#context-biasing).
- `language`: Our transcription service also works as a language detection service. However, you can manually set the language of the transcription for better accuracy if the language of the audio is already known.

**Realtime**:
We provide a live transcription functionality. You can find more info about Realtime [here](#realtime-transcription).

<ExplorerTabs id="audio-transcription-3">
  <ExplorerTab value="passing-an-audio-file" label="Passing an Audio File">
    <PassingTranscriptionAudioFileTab/>
  </ExplorerTab>
  <ExplorerTab value="passing-an-audio-url" label="Passing an Audio URL">
    <PassingTranscriptionAudioURLTab/>
  </ExplorerTab>
  <ExplorerTab value="passing-an-uploaded-audio-file" label="Passing an Uploaded Audio File">
    <PassingTranscriptionUploadedAudioFileTab/>
  </ExplorerTab>
</ExplorerTabs>

<SectionTab as="h2" variant="secondary" sectionId="example-samples">Example Samples</SectionTab>

Below you can find a few examples leveraging the audio transcription endpoint.

<ExplorerTabs id="audio-transcription-4" mode="close">
  <ExplorerTab value="obama" label="Obama">
    <ObamaTab/>
  </ExplorerTab>
</ExplorerTabs>

<TranscriptionWithTimestampsSection/>

<ContextBiasingSection/>

<RealtimeTranscriptionSection/>

<SectionTab as="h1" sectionId="faq">FAQ</SectionTab>

<Faq>
  <FaqItem question="What's the maximum audio length?">

    The maximum length will depend on the endpoint used, currently the limits are as follows:
    - [Chat with Audio](#chat-with-audio): ≈20 minutes for [Voxtral Mini Transcribe](/../../models/voxtral-mini-transcribe-25-07) and [Voxtral Small](/../../models/voxtral-small-25-07).
    - [Transcription](#transcription): ≈15 minutes for [Voxtral Mini Transcribe](/../../models/voxtral-mini-transcribe-25-07) and [Voxtral Small](/../../models/voxtral-small-25-07), and ≈30 minutes for [Voxtral Mini Transcribe 2](/../../models/voxtral-mini-transcribe-26-02).

    :::tip
    Here are some tips if you need to handle longer audio files:
    - **Divide the audio into smaller segments:** Transcribe each segment individually. However, be aware that this might lead to a loss of context, difficulties in splitting the audio at natural pauses (such as mid-sentence), and the need to combine the transcriptions afterward.
    - **Increase the playback speed:** Send the file at a faster pace by speeding up the audio. Keep in mind that this can reduce audio quality and require adjusting the transcription timestamps to align with the original audio file.
    :::

  </FaqItem>
</Faq>
