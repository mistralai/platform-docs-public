---
id: finetuning_overview
title: Fine-tuning Overview
slug: finetuning_overview
---

:::warning[ ]
Every fine-tuning job comes with a minimum fee of $4, and there's a monthly storage fee of $2 for each model. For more detailed pricing information, please visit our [pricing page](https://mistral.ai/technology/#pricing). 
:::

## Fine-tuning Basics

### Fine-tuning vs. Prompting 

When deciding whether to use prompt engineering or fine-tuning for an AI model, it can be difficult to determine which method is best. It's generally recommended to start with prompt engineering, as it's faster and less resource-intensive. To help you choose the right approach, here are the key benefits of prompting and fine-tuning:

- **Benefits of Prompting**
    - A generic model can work out of the box (the task can be described in a zero shot fashion)
    - Does not require any fine-tuning data or training to work
    - Can easily be updated for new workflows and prototyping
  
  Check out our [prompting guide](https://docs.mistral.ai/guides/prompting_capabilities/) to explore various capabilities of Mistral models. 

- **Benefits of Fine-tuning**
    - Works significantly better than prompting
    - Typically works better than a larger model (faster and cheaper because it doesn't require a very long prompt)
    - Provides a better alignment with the task of interest because it has been specifically trained on these tasks 
    - Can be used to teach new facts and information to the model (such as advanced tools or complicated workflows)

### Common use cases

Fine-tuning has a wide range of use cases, some of which include:
- Customizing the model to generate responses in a specific format and tone
- Specializing the model for a specific topic or domain to improve its performance on domain-specific tasks
- Improving the model through distillation from a stronger and more powerful model by training it to mimic the behavior of the larger model 
- Enhancing the modelâ€™s performance by mimicking the behavior of a model with a complex prompt, but without the need for the actual prompt, thereby saving tokens, and reducing associated costs
- Reducing cost and latency by using a small yet efficient fine-tuned model

## Fine-tuning Services
- [Text & Vision General Fine-tuning](../text_vision_finetuning):
    - **SFT**: Supervised Fine-tuning, the most common fine-tuning method to teach the model knowledge and how to follow instructions.
- [Classifier Factory](../classifier_factory): A tool to finetune and create classifier specific models from a dataset of text.